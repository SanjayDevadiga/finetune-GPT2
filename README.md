# finetune-GPT2
Notebook to finetune GPT 2 model with the custom dataset

-> Configured to finetune with 16 GB GPU and minimum 36 GB RAM 
-> Resource requirement depends on the amount of data you are using for finetuning the model
-> Huggingface transformers method is used to finetune the model here
-> Just a small dataset to quickly check the progress
